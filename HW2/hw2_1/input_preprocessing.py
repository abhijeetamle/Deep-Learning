# -*- coding: utf-8 -*-
"""input_preprocessing.ipynb

Automatically generated by Colaboratory.

"""

import numpy as np
import os
import sys
from os import listdir
import json
import pickle
import io

"""## Function to create a dictionary for captions"""

def build_dictionary(sentences, min_count):

    word_counts = {}
    sentences_count = 0
    for sentence in sentences:
        sentences_count += 1
        for word in sentence.lower().split(' '):
            word_counts[word] = word_counts.get(word, 0) + 1
    
    # adding words to a list if it occurs more than or equal to min_count=3
    dictionary = [word for word in word_counts if word_counts[word] >= min_count]
    print ('Filtered words from %d to %d with min_count of %d' % (len(word_counts), len(dictionary), min_count))

    # pad - padding to make all sentences of equal length (padding will be applied before training)
    # bos - starting of a sentence
    # eos - ending of a sentence 
    # unk - unknown for the dictionary (or word cannot store to dictionary)

    # dict – maps indices to their respective words
    index2word = {}
    index2word[0] = '<pad>'
    index2word[1] = '<bos>'
    index2word[2] = '<eos>'
    index2word[3] = '<unk>'

    # dict – maps words to their respective indices
    word2index = {}
    word2index['<pad>'] = 0
    word2index['<bos>'] = 1
    word2index['<eos>'] = 2
    word2index['<unk>'] = 3

    for index, word in enumerate(dictionary):
        word2index[word] = index + 4
        index2word[index + 4] = word

    return word2index, index2word, dictionary

"""### Function to remove special symbols from captions"""

def filter_token(string):
    # Filter characters
    filters = '!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n'
    for c in filters:
        string = string.replace(c, '')
    return string

if __name__ == "__main__":
    np.random.seed(9487)

    # video features
    video_feat_folder = '/content/drive/My Drive/Deep_Learning/MLDS_hw2_1_data/training_data/feat/'

    # video captions
    training_label_json_file = '/content/drive/My Drive/Deep_Learning/MLDS_hw2_1_data/training_label.json'

    # listing all video features
    video_feat_filenames = listdir(video_feat_folder)
    video_feat_filepaths = [(video_feat_folder + filename) for filename in video_feat_filenames]

    # removing '.avi' from filename
    video_IDs = [filename[:-4] for filename in video_feat_filenames]

    video_feat_dict = {}
    for filepath in video_feat_filepaths:
        video_feat = np.load(filepath)
        video_ID = filepath[: -4].replace(video_feat_folder, "")
        video_feat_dict[video_ID] = video_feat
    
    # loading captions for all videos
    video_caption = json.load(open(training_label_json_file, 'r'))
    video_caption_dict={}
    captions_corpus = []

    # iterating through json to get all the captions for each video
    for video in video_caption:
        filtered_captions = [filter_token(sentence) for sentence in video["caption"]]
        video_caption_dict[video["id"]] = filtered_captions
        captions_corpus += filtered_captions

    # building a dictionary for video captions
    word2index, index2word, dictionary = build_dictionary(captions_corpus, min_count=3)
    
    # saving vocabulary objects for training
    pickle.dump(word2index, open('/content/drive/My Drive/Deep_Learning/Training1/word2index.obj', 'wb'))
    pickle.dump(index2word, open('/content/drive/My Drive/Deep_Learning/Training1/index2word.obj', 'wb'))

    # saving video IDs, video caption dictionary, and video feature dictionary for training
    pickle.dump(video_IDs, open('/content/drive/My Drive/Deep_Learning/Training1/video_IDs.obj', 'wb'))
    pickle.dump(video_caption_dict, open('/content/drive/My Drive/Deep_Learning/Training1/video_caption_dict.obj', 'wb'))
    pickle.dump(video_feat_dict, open('/content/drive/My Drive/Deep_Learning/Training1/video_feat_dict.obj', 'wb'))

    print('Objects saved.')
    print('Input data preprocessing completed.')



