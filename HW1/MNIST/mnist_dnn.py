# -*- coding: utf-8 -*-
"""mnist_dnn.ipynb

Automatically generated by Colaboratory.

"""

# Commented out IPython magic to ensure Python compatibility.
#specifying tensorflow version 1.x for 1.15.0
# %tensorflow_version 1.x
import tensorflow as tf
print(tf.__version__)
#import MNIST dataset handle from tensorflow and same data in one hot encoded format
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)

"""**To check whether MNIST dataset got loaded or not**

running the below cell will show few images with their labels from the dataset
"""

# Commented out IPython magic to ensure Python compatibility.
data = mnist.train.next_batch(5)
images = data[0]
labels = data[1]

# import matplotlib for visualization
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline

for index, image in enumerate(images):
    print( 'Label:', labels[index])
    print( 'Digit in the image', np.argmax(labels[index]))
    plt.imshow(image.reshape(28,28),cmap='gray')
    plt.show()

print("Size of:")
print("- Training-set:\t\t{}".format(len(mnist.train.labels)))
print("- Test-set:\t\t{}".format(len(mnist.test.labels)))
print("- Validation-set:\t{}".format(len(mnist.validation.labels)))

"""**Defining placeholder**"""

# x is a input with 28x28 pixels = 784
x = tf.placeholder(tf.float32, shape=[None, 784])
print('x.get_shape(): {}'.format(x.get_shape()))

x_m2 = tf.placeholder(tf.float32, shape=[None, 784])

# y is an output with 10 digits

y = tf.placeholder(tf.float32, shape=[None, 10])
y_m2 = tf.placeholder(tf.float32, shape=[None, 10])

y_true_cls = tf.argmax(y, dimension=1)
y_true_cls_m2 = tf.argmax(y_m2, dimension=1)

keep_prob = tf.placeholder(tf.float32)

"""**Function to create fully connected layer**"""

def create_fully_connected_layer(x, num_output, activation_fun=None, name=None):

    # creating the weights
    weight = tf.get_variable(initializer=tf.random_normal([x.get_shape()[-1].value, num_output], stddev=0.0999), name=name+'/weight')

    # creating the bias
    bias = tf.get_variable(shape=[num_output],initializer=tf.constant_initializer(0.1), name=name+'/bias')
    
    # Calculate sum of neurons
    sum = tf.matmul(x,weight) + bias
        
    # applying activation function if required
    if activation_fun:
      sum = activation_fun(sum)

    return sum

"""**Designing the network**"""

# Model 1

# layer 1: number of inputs = 28 * 28
# Activation function: ReLU

dense_layer1 = create_fully_connected_layer(x, 784, tf.nn.relu, name='dense_layer1')

# Dropout with rate=1-0.6

drop_dense_layer1 = tf.nn.dropout(dense_layer1, 0.6)

# layer 2: number of nodes = 128
# Activation function: ReLU

dense_layer2 = create_fully_connected_layer(drop_dense_layer1, 128, tf.nn.relu, name='dense_layer2')

# logits: number of nodes = 10
# Activation function: Softmax applied in the next step

last_layer = create_fully_connected_layer(dense_layer2, 10, name='dense_layer3')

# Model 2

logit = create_fully_connected_layer(x_m2, 10, name='layer_logit')

# Model 1

y_pred = tf.nn.softmax(logits=last_layer)
y_pred_cls = tf.argmax(y_pred, dimension=1)

# Model 2 

y_pred_m2 = tf.nn.softmax(logits=logit)
y_pred_cls_m2 = tf.argmax(y_pred_m2, dimension=1)

# Getting shapes of all layers of Model 1

print(dense_layer1.get_shape())
print(dense_layer2.get_shape())
print(last_layer.get_shape())

# Getting shapes of Model 2

print(logit.get_shape())

"""**Define loss and optimizer**"""

# Defining loss

# Model 1

cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=last_layer)
loss = tf.reduce_mean(cross_entropy)

# Model 2 

cross_entropy_m2 = tf.nn.softmax_cross_entropy_with_logits(labels=y_m2, logits=logit)
loss_m2 = tf.reduce_mean(cross_entropy_m2)

# Adding an optimizer

# Model 1

opt = tf.train.AdamOptimizer(learning_rate=0.0009)
optimizer = opt.minimize(loss)

# Model 2

opt_m2 = tf.train.AdamOptimizer(learning_rate=0.0015)
optimizer_m2 = opt_m2.minimize(loss_m2)

# Defining accuracy

# Model 1

correct_pred = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# Model 2

correct_pred_m2 = tf.equal(y_pred_cls_m2, y_true_cls_m2)
accuracy_m2 = tf.reduce_mean(tf.cast(correct_pred_m2, tf.float32))

"""**Getting the weights**"""

print (tf.trainable_variables())

# Function for getting weights from the network
def get_weights_variable(layer_name):

    with tf.variable_scope(layer_name, reuse=True):
        variable = tf.get_variable('weight')

    return variable

# Model 1

weights_fc1 = get_weights_variable(layer_name='dense_layer1')
print(weights_fc1)

weights_fc2 = get_weights_variable(layer_name='dense_layer2')
print(weights_fc2)

weights_fc_out = get_weights_variable(layer_name='dense_layer3')
print(weights_fc_out)

# Model 2

weights_logit = get_weights_variable(layer_name='layer_logit')
print(weights_logit)

"""**Creating a Tensorflow session**"""

#create a tensorflow session
sess = tf.Session()

"""**Initializing the variables**"""

sess.run(tf.global_variables_initializer())

"""**Getting Gradients**"""

# Model 1

grads = tf.gradients(loss, weights_fc_out)[0]
print(grads)

# Model 2

grads_m2 = tf.gradients(loss_m2, weights_logit)[0]
print(grads_m2)

# Function to calculate grad norm
def calculate_grad_norm(grads_vals):

  grad_all = 0.0

  for gv in grads_vals:
    gd = sum(gv**2)
    grad_all += gd

  grad_norm = grad_all ** 0.5
#  print(grad_norm)

  return grad_norm

"""**Computing Hessian**"""

hessian = tf.reduce_sum(tf.hessians(loss, weights_fc_out)[0], axis = 2)
print(hessian)

hessian_m2 = tf.reduce_sum(tf.hessians(loss_m2, weights_logit)[0], axis = 2)
print(hessian_m2)

"""**Training the network**"""

total_epoch=8
batch_size = 64
total_batch_size = int(len(mnist.train.labels) / batch_size)
print('total mnist training labels: {}'.format(len(mnist.train.labels)))
print('total_batch_size: {}'.format(total_batch_size))

grad_arr, iteration_arr, train_loss_arr, train_accuracy_arr, weights_fc_out_arr, weights_fc_1_arr, weights_fc_2_arr = [], [], [], [], [], [], []
grad_arr_m2,  train_loss_arr_m2, train_accuracy_arr_m2, weights_logit_arr_m2 = [], [], [], []
iteration_ctr = 0

%%time
for epoch in range(total_epoch):

  print('Starting epoch: {}\n'.format(epoch+1))

  for batch_ctr in range(total_batch_size):

    # Fetching a batch size of 64 images
    x_batch, y_true_batch = mnist.train.next_batch(batch_size)

    # Shuffle the labels before training 
#    np.random.shuffle(y_true_batch)

    feed_dict_train = {x: x_batch, y: y_true_batch}
    feed_dict_train_m2 = {x_m2: x_batch, y_m2: y_true_batch}

    # run training for each iteration
    sess.run(optimizer, feed_dict={x: x_batch, y: y_true_batch, keep_prob: 0.5})
    sess.run(optimizer_m2, feed_dict={x_m2: x_batch, y_m2: y_true_batch, keep_prob: 0.5})

  
    # Every 10 steps, compute loss and accuracy of training, and calculate gradient norm and hessian
    if batch_ctr % 10 == 0:

      global iteration_ctr
      iteration_ctr +=1
      iteration_arr.append(iteration_ctr)

      train_loss, train_accuracy = sess.run([loss, accuracy], feed_dict=feed_dict_train)
      train_loss_m2, train_accuracy_m2 = sess.run([loss_m2, accuracy_m2], feed_dict=feed_dict_train_m2)

      train_accuracy_arr.append(train_accuracy)
      train_loss_arr.append(train_loss)

      train_accuracy_arr_m2.append(train_accuracy_m2)
      train_loss_arr_m2.append(train_loss_m2)

      # Computing gradient and hessian

      grads_vals, hess_vals = sess.run([grads, hessian], feed_dict=feed_dict_train)
      grads_vals_m2, hess_vals_m2 = sess.run([grads_m2, hessian_m2], feed_dict=feed_dict_train_m2)

      # Calculate gradient norm
      grad_norm = calculate_grad_norm(grads_vals)
      grad_arr.append(grad_norm)

      grad_norm_m2 = calculate_grad_norm(grads_vals_m2)
      grad_arr_m2.append(grad_norm_m2)

      # after every 100 iterations print trainig loss and accuracy
      if batch_ctr % 100 == 0:
        print('Iteration {:>6}   Training Loss {:>1.6}  Training Accuracy {:>6.1%}'.format(batch_ctr+1, train_loss, train_accuracy))
        print('Iteration M2 {:>6} Training Loss M2 {:>1.6}  Training Accuracy M2 {:>6.1%}\n'.format(batch_ctr+1, train_loss_m2, train_accuracy_m2))

    # after every 3 epochs collect weights
    if epoch % 3 == 0:
      
    # Model 1

      weights_fc_1_tensor = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='dense_layer1/weight:0')
      weights_fc_1_values = sess.run(weights_fc_1_tensor, feed_dict=feed_dict_train)
      weights_fc_1_arr.append(weights_fc_1_values)

      weights_fc_2_tensor = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='dense_layer2/weight:0')
      weights_fc_2_values = sess.run(weights_fc_2_tensor, feed_dict=feed_dict_train)
      weights_fc_2_arr.append(weights_fc_2_values)

      weights_fc_out_tensor = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='dense_layer3/weight:0')
      weights_fc_out_values = sess.run(weights_fc_out_tensor, feed_dict=feed_dict_train)
      weights_fc_out_arr.append(weights_fc_out_values)

    # Model 2

      weights_logit_tensor_m2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='layer_logit/weight:0')
      weights_logit_values_m2 = sess.run(weights_logit_tensor_m2, feed_dict=feed_dict_train_m2)
      weights_logit_arr_m2.append(weights_logit_values_m2)

    

print('\nIteration {:>6} Training Loss {:>1.6} Training Accuracy {:>6.1%}'.format(batch_ctr+1, train_loss, train_accuracy))
print('Iteration M2 {:>6} Training Loss M2 {:>1.6} Training Accuracy M2 {:>6.1%}\n'.format(batch_ctr+1, train_loss_m2, train_accuracy_m2))

"""## Plotting graphs"""

# as we are computing loss and accuracy every 10th iteration, so iteration should be equal to the total number of iterations actually performed 
iteration_arr = np.array(iteration_arr)
iteration_arr = iteration_arr * 10

# Training loss vs Iteration

plt.plot(iteration_arr, train_loss_arr, 'r', label = "Training loss model 1")
plt.plot(iteration_arr, train_loss_arr_m2, 'b', label = "Training loss Model 2")
plt.xlabel('Iterations')
plt.ylabel('Training loss')
plt.title('Total Epoch: {}'.format(total_epoch))
plt.legend()
plt.show();

# Training loss and accuracy vs Iterations for Model 1

fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.suptitle('Training history Model 1')
ax1.plot(iteration_arr, train_loss_arr, 'r')
ax2.plot(iteration_arr, train_accuracy_arr)
plt.xlabel('Iterations')
ax1.set_ylabel('Loss')
ax2.set_ylabel('Accuracy')
plt.show();

# Training loss and accuracy vs Iterations for Model 2

fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.suptitle('Training history Model 2')
ax1.plot(iteration_arr, train_loss_arr_m2)
ax2.plot(iteration_arr, train_accuracy_arr_m2)
plt.xlabel('Iterations')
ax1.set_ylabel('Loss')
ax2.set_ylabel('Accuracy')
plt.show();

# Training accuracy vs Iterations

plt.plot(iteration_arr, train_accuracy_arr, 'r', label = "Training Accuracy Model 1")
plt.plot(iteration_arr, train_accuracy_arr_m2, 'b', label = "Training Accuracy Model 2")
plt.xlabel('Iterations')
plt.ylabel('Training Accuracy')
plt.title('Total Epoch: {}'.format(total_epoch))
plt.legend()
plt.show();

# Gradient norm and loss vs total iterations for Model 1

fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.suptitle('Model 1')
ax1.plot(iteration_arr, grad_arr)
ax2.plot(iteration_arr, train_loss_arr, 'r')
plt.xlabel('Iterations')
ax1.set_ylabel('grad')
ax2.set_ylabel('loss')
plt.show();

# Gradient norm and loss vs total iterations for Model 2

fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.suptitle('Model 2')
ax1.plot(iteration_arr, grad_arr_m2)
ax2.plot(iteration_arr, train_loss_arr_m2, 'r')
plt.xlabel('Iterations')
ax1.set_ylabel('grad')
ax2.set_ylabel('loss')
plt.show();

"""### Testing accuracy on test data"""

mnist.test.cls = np.argmax(mnist.test.labels, axis=1)

# Split the test-set into smaller batches of batch size equals to 256
test_batch_size = 256

def print_test_accuracy():

    # Number of images in the test-set.
    num_test = len(mnist.test.images)

    # Allocate an array for the predicted classes which
    # will be calculated in batches and filled into this array.
    cls_pred = np.zeros(shape=num_test, dtype=np.int)
    cls_pred_m2 = np.zeros(shape=num_test, dtype=np.int)

    # The starting index for the next batch is denoted i.
    i = 0

    # iterating through all the batches
    while i < num_test:
        # The ending index for the next batch is denoted j.
        j = min(i + test_batch_size, num_test)

        # Get the images from the test-set between index i and j.
        images = mnist.test.images[i:j, :]

        # Get the associated labels.
        labels = mnist.test.labels[i:j, :]

        # Create a feed-dict with these images and labels.
        feed_dict = {x: images,
                     y: labels}

        feed_dict_m2 = {x_m2: images,
                     y_m2: labels}

        # Calculate the predicted class using TensorFlow.
        cls_pred[i:j] = sess.run(y_pred_cls, feed_dict=feed_dict)
        cls_pred_m2[i:j] = sess.run(y_pred_cls_m2, feed_dict=feed_dict_m2)

        # Set the start-index for the next batch to the
        # end-index of the current batch.
        i = j

    # Convenience variable for the true class-numbers of the test-set.
    cls_true = mnist.test.cls

    # Create a boolean array whether each image is correctly classified.
    correct = (cls_true == cls_pred)
    correct_m2 = (cls_true == cls_pred_m2)

    # Calculate the number of correctly classified images.
    # When summing a boolean array, False means 0 and True means 1.
    correct_sum = correct.sum()
    correct_sum_m2 = correct_m2.sum()

    # Classification accuracy is the number of correctly classified
    # images divided by the total number of images in the test-set.
    acc = float(correct_sum) / num_test
    acc_m2 = float(correct_sum_m2) / num_test

    # Print the accuracy.
    msg = "Accuracy on Test-Set for Model 1: {0:.2%} ({1} / {2})"
    print(msg.format(acc, correct_sum, num_test))

    msg_m2 = "Accuracy on Test-Set for Model 2: {0:.2%} ({1} / {2})"
    print(msg_m2.format(acc_m2, correct_sum_m2, num_test))

print_test_accuracy()

"""## Principal component analysis (PCA)"""

from sklearn.decomposition import PCA
def plot_fc_weights(weights_list):
    
    # Retrieving the values of the weight-variables from TensorFlow.
    w_list = []
    for element in weights_list:

      w_list_var = sess.run(element)
      w_list.append(w_list_var)
    
    pca = PCA(n_components=2)
    
    fig = plt.figure(figsize = (8,8))
    ax = fig.add_subplot(1,1,1) 
    ax.set_xlabel('Principal Component 1', fontsize = 15)
    ax.set_ylabel('Principal Component 2', fontsize = 15)
    
    for w in w_list:

#        print(w.shape)
        principalComponents = pca.fit_transform(w)
        ax.scatter(principalComponents[:,0], principalComponents[:,1], label=w.shape, alpha=0.5)

    ax.legend()
    plt.show()

plot_fc_weights(weights_list=[weights_fc2,  weights_fc_out])

plot_fc_weights(weights_list=[weights_fc1, weights_fc2, weights_fc_out])

"""## Testing accuracy on shuffled labels during training for Model 1"""

loss_validation_arr = []
loss_validation_ctr = 0

# Split the test-set into smaller batches of 64 size.

test_batch_size = 64

def print_test_accuracy_shuffle_label():

    # Number of images in the test-set.
    num_test = len(mnist.test.images)

    # Allocate an array for the predicted classes which
    # will be calculated in batches and filled into this array.
    cls_pred = np.zeros(shape=num_test, dtype=np.int)

    # The starting index for the next batch is denoted i.
    i = 0

    while i < num_test:

        # The ending index for the next batch is denoted j.
        j = min(i + test_batch_size, num_test)

        # Get the images from the test-set between index i and j.
        images = mnist.test.images[i:j, :]

        # Get the associated labels.
        labels = mnist.test.labels[i:j, :]

        # Create a feed-dict with these images and labels.
        feed_dict = {x: images, y: labels}


        # Calculate the predicted class using TensorFlow.
        loss_validation, cls_pred[i:j] = sess.run([loss, y_pred_cls], feed_dict=feed_dict)
        
        loss_validation_arr.append(loss_validation)

        # Set the start-index for the next batch to the
        # end-index of the current batch.
        i = j

    # Convenience variable for the true class-numbers of the test-set.
    cls_true = mnist.test.cls

    # Create a boolean array whether each image is correctly classified.
    correct = (cls_true == cls_pred)

    # Calculate the number of correctly classified images.
    # When summing a boolean array, False means 0 and True means 1.
    correct_sum = correct.sum()

    # Classification accuracy is the number of correctly classified
    # images divided by the total number of images in the test-set.
    acc = float(correct_sum) / num_test

    # Print the accuracy.
#    msg = "Accuracy on Test-Set for Model 1: {0:.2%} ({1} / {2})"
#    print(msg.format(acc, correct_sum, num_test))

# 1 Epoch of training is 859 iterations
# Test set contains 10000 images 
# Batch of 64 images will give 156 iterations
# so for every 1 epoch we need to check accuracy nearly 5 times for matching number of iterations
# for 200 epochs of training, run below for loop 1000 times

for i in range(total_epoch*5):
  print_test_accuracy_shuffle_label()

"""## Plotting Training and Validation loss after label shuffling"""

# Plotting Training loss and Validation loss vs number of iterations for Model 1

val_ctr_arr = [i for i in range(len(loss_validation_arr))]
plt.plot(iteration_arr, train_loss_arr, 'r', label = "Training loss")
plt.plot(val_ctr_arr, loss_validation_arr, 'g', label = "Validation loss")
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.title('Total Epoch: {}'.format(total_epoch))
plt.legend()
plt.show();

