# -*- coding: utf-8 -*-
"""mnist_CNN.ipynb

Automatically generated by Colaboratory.

"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import tensorflow as tf

#import MNIST dataset handle from tensorflow and same data in one hot encoded format
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
tf.__version__

"""**To check whether MNIST dataset got loaded or not**

running the below cell will show few images with their labels from the dataset
"""

# Commented out IPython magic to ensure Python compatibility.
data = mnist.train.next_batch(5)
images = data[0]
labels = data[1]

# import matplotlib for visualization
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline

for index, image in enumerate(images):
    print( 'Label:', labels[index])
    print( 'Digit in the image', np.argmax(labels[index]))
    plt.imshow(image.reshape(28,28),cmap='gray')
    plt.show()

print("Size of:")
print("- Training-set:\t\t{}".format(len(mnist.train.labels)))
print("- Test-set:\t\t{}".format(len(mnist.test.labels)))
print("- Validation-set:\t{}".format(len(mnist.validation.labels)))

"""**Defining placeholder**"""

# x is a input with 28x28 pixels = 784
x = tf.placeholder(tf.float32, shape=[None, 784])
print('x.get_shape(): {}'.format(x.get_shape()))

# y is an output with 10 digits
y = tf.placeholder(tf.float32, shape=[None, 10])

# Reshaping the array to 4-dims so that it can work with TensorFlow convolution and pooling functions
input_tensor = tf.reshape(x, [-1,28,28,1])
print('input_tensor.get_shape(): {}'.format(input_tensor.get_shape()))

y_true_cls = tf.argmax(y, dimension=1)

keep_prob = tf.placeholder(tf.float32)

"""**Function to create convolution layer**"""

# Function to create convolution layer then performing max pool with stride of 2x2
def create_convolution_layer(input_tensor, num_input_channels, num_filters, kernel, stride, name):

    # for tf.nn.conv2d creating the input shape filter
    conv_filter_shape = [kernel[0], kernel[1], num_input_channels, num_filters]

    # creating the weights
    weight = tf.get_variable(initializer=tf.random_normal(conv_filter_shape, stddev=0.0999), name=name+'/weight')
    
    # creating the bias
    bias = tf.get_variable(shape=[num_filters],initializer=tf.constant_initializer(0.1), name=name+'/bias')

    # setup the convolutional layer operation using weights
    con = tf.nn.conv2d(input_tensor, weight, strides=[1, 1, 1, 1], padding='SAME')
    
    # Define activation operation: add a bias to the output of the convolutional filter, then apply a ReLU non-linear activation function
    activation = tf.nn.relu(tf.nn.bias_add(con, bias))

    # performing max pooling on activation
    # here we are using a 2Ã—2 max pooling window size

    activation = tf.nn.max_pool(value=activation,
                                ksize=[1, 2, 2, 1],
                                strides=[1, 2, 2, 1],
                                padding='SAME')
    
    return activation

"""**Function for flattening**"""

# we have to flatten the output from the last convolutional layer to 1D array as the input to fully connected layers

def flatten(x):    
    
    input_shape=x.get_shape()
    flatten_num = 1
    for index in range(len(input_shape)-1):
        flatten_num *= input_shape[1-len(input_shape)+index].value
    x = tf.reshape(x, [-1,flatten_num])

    print('flatten: {}'.format(x.get_shape()))
    
    return x

"""**Function to create fully connected layer**"""

def create_fully_connected_layer(x, num_output, activation_fun=None, name=None):

    # creating the weights
    weight = tf.get_variable(initializer=tf.random_normal([x.get_shape()[-1].value, num_output], stddev=0.0999), name=name+'/weight')

    # creating the bias
    bias = tf.get_variable(shape=[num_output],initializer=tf.constant_initializer(0.1), name=name+'/bias')
    
    # Calculate sum of neurons
    sum = tf.matmul(x,weight) + bias
        
    # applying activation function if required
    if activation_fun:
      sum = activation_fun(sum)

    return sum

"""**Designing the network**"""

# Creating convolution layers

    # layer 1: 5x5 conv, 1 input, 36 outputs
      #   name = conv_layer1
      #   input = input_tensor
      #   num_input_channels = 1
      #   num_filters = 36
      #   kernel = [5,5]
      #   stride = [2,2]

conv_layer1 = create_convolution_layer(input_tensor, 1, 36, [5, 5], [2, 2],name='conv_layer1')

# Max pooling 2x2 applied in the function create_convolution_layer

    # layer 2: 5x5 conv, 36 input, 36 outputs
      #   name = conv_layer2
      #   input = conv_layer1
      #   num_input_channels = 36
      #   num_filters = 36
      #   kernel = [5,5]
      #   stride = [2,2]

conv_layer2 = create_convolution_layer(conv_layer1, 36, 36, [5,5], [2,2],name='conv_layer2')

# Max pooling 2x2 applied in the function create_convolution_layer

    # layer 3: 5x5 conv, 36 input, 36 outputs
      #   name = conv_layer3
      #   input = conv_layer2
      #   num_input_channels = 36
      #   num_filters = 36
      #   kernel = [5,5]
      #   stride = [2,2]

conv_layer3 = create_convolution_layer(conv_layer2, 36, 36, [5,5], [2,2],name='conv_layer3')

# Max pooling 2x2 applied in the function create_convolution_layer

# Dropout with rate=1-0.75
drop_conv_layer3 = tf.nn.dropout(conv_layer3, 0.75)

# Flattening output to 1D array

flatten_output = flatten(drop_conv_layer3)

# Creating fully connected dense layers

    # layer 1: 
    # number of hidden layer neurons = 576
    # Activation function = ReLU

dense_layer1 = create_fully_connected_layer(flatten_output, 576, tf.nn.relu, name='dense_layer1')

# Dropout with rate=1-0.75
drop_dense_layer1 = tf.nn.dropout(dense_layer1, 0.75)

    # logits: 
    # number of output nodes = 10
    # Activation function softmax applied in the next step

last_layer = create_fully_connected_layer(drop_dense_layer1, 10, name='dense_layer2')

# Applying softmax activation function to logits

y_pred = tf.nn.softmax(logits=last_layer)
y_pred_cls = tf.argmax(y_pred, dimension=1)

# checking the shape of each layer

print(conv_layer1.get_shape())
print(conv_layer2.get_shape())
print(dense_layer1.get_shape())
print(last_layer.get_shape())

"""**Counting total parameters**"""

total_parameters = 0
  for variable in tf.trainable_variables():
      # shape is an array of tf.Dimension
      print(variable)
      shape = variable.get_shape()
      print(shape)
      #print(len(shape))
      variable_parameters = 1
      for dim in shape:
          #print(dim)
          variable_parameters *= dim.value
      print(variable_parameters)
      total_parameters += variable_parameters
  print(total_parameters)

"""**Define loss and optimizer**"""

# Defining loss

cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=last_layer)
loss = tf.reduce_mean(cross_entropy)

# Adding an optimizer

opt = tf.train.AdamOptimizer(learning_rate=0.0001)
optimizer = opt.minimize(loss)

# Defining accuracy

correct_pred = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

"""**Getting the weights**"""

print (tf.trainable_variables())

# Function for getting weights from the network
def get_weights_variable(layer_name):

    with tf.variable_scope(layer_name, reuse=True):
        variable = tf.get_variable('weight')

    return variable

weights_conv1 = get_weights_variable(layer_name='conv_layer1')
print(weights_conv1)

weights_conv2 = get_weights_variable(layer_name='conv_layer2')
print(weights_conv2)

weights_fc1 = get_weights_variable(layer_name='dense_layer1')
print(weights_fc1)

weights_fc_out = get_weights_variable(layer_name='dense_layer2')
print(weights_fc_out)

"""**Creating a Tensorflow session**"""

#create a tensorflow session
sess = tf.Session()

"""**Initializing the variables**"""

sess.run(tf.global_variables_initializer())

"""**Training the network**"""

total_epoch=8
batch_size = 64
total_batch_size = int(len(mnist.train.labels) / batch_size)
print('total mnist training labels: {}'.format(len(mnist.train.labels)))
print('total_batch_size: {}'.format(total_batch_size))

grad_arr, iteration_arr, train_loss_arr, train_accuracy_arr = [], [], [], []
iteration_ctr = 0

%%time
for epoch in range(total_epoch):

  print('Starting epoch: {}'.format(epoch+1))

  for batch_ctr in range(total_batch_size):

    # Fetching a batch size of 64 images
    x_batch, y_true_batch = mnist.train.next_batch(batch_size)

    feed_dict_train = {x: x_batch, y: y_true_batch}

    # run training for each iteration
    sess.run(optimizer, feed_dict={x: x_batch, y: y_true_batch, keep_prob: 0.5})

    # Every 10 steps, compute the loss and accuracy of training
    if batch_ctr % 10 == 0:
	
      train_loss, train_accuracy = sess.run([loss, accuracy], feed_dict=feed_dict_train)

      train_accuracy_arr.append(train_accuracy)
      train_loss_arr.append(train_loss)

      global iteration_ctr
      iteration_ctr +=1
      iteration_arr.append(iteration_ctr)
      
      # Every 100 steps, print the loss and accuracy of training
      if batch_ctr % 100 == 0:
        print('Iteration {:>6}   Training Loss {:>1.6}  Training Accuracy {:>6.1%}'.format(batch_ctr+1, train_loss, train_accuracy))

print('Iteration {:>6} Training Loss {:>1.6} Training Accuracy {:>6.1%}'.format(batch_ctr+1, train_loss, train_accuracy))

"""## Plotting graphs"""

# loss and accuracy was computed after every 10 setps, so iteration should be equal to total number of actual iterations
iteration_arr = np.array(iteration_arr)
iteration_arr = iteration_arr * 10

# Training loss vs Iteration

plt.plot(iteration_arr, train_loss_arr, 'g', label = "Training loss CNN")
plt.xlabel('Iteration')
plt.ylabel('Training loss')
plt.legend()
plt.show();

# Training loss and accuracy vs Iterations

fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.suptitle('Training history')
ax1.plot(iteration_arr, train_loss_arr, 'r')
ax2.plot(iteration_arr, train_accuracy_arr)
plt.xlabel('Iterations')
ax1.set_ylabel('Loss')
ax2.set_ylabel('Accuracy')
plt.show();

"""### Testing accuracy on test data"""

mnist.test.cls = np.argmax(mnist.test.labels, axis=1)

# Split the test-set into smaller batches of batch size equals to 256
test_batch_size = 256

def print_test_accuracy():

    # Number of images in the test-set.
    num_test = len(mnist.test.images)

    # Allocate an array for the predicted classes which
    # will be calculated in batches and filled into this array.
    cls_pred = np.zeros(shape=num_test, dtype=np.int)

    # The starting index for the next batch is denoted i.
    i = 0

    # iterating through all the batches
    while i < num_test:
        # The ending index for the next batch is denoted j.
        j = min(i + test_batch_size, num_test)

        # Get the images from the test-set between index i and j.
        images = mnist.test.images[i:j, :]

        # Get the associated labels.
        labels = mnist.test.labels[i:j, :]

        # Create a feed-dict with these images and labels.
        feed_dict = {x: images,
                     y: labels}

        # Calculate the predicted class using TensorFlow.
        cls_pred[i:j] = sess.run(y_pred_cls, feed_dict=feed_dict)

        # Set the start-index for the next batch to the
        # end-index of the current batch.
        i = j

    # Convenience variable for the true class-numbers of the test-set.
    cls_true = mnist.test.cls

    # Create a boolean array whether each image is correctly classified.
    correct = (cls_true == cls_pred)

    # Calculate the number of correctly classified images.
    # When summing a boolean array, False means 0 and True means 1.
    correct_sum = correct.sum()

    # Classification accuracy is the number of correctly classified
    # images divided by the total number of images in the test-set.
    acc = float(correct_sum) / num_test

    # Print the accuracy.
    msg = "Accuracy on Test-Set: {0:.2%} ({1} / {2})"
    print(msg.format(acc, correct_sum, num_test))

print_test_accuracy()

