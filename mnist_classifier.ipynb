{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSiaAyeX+Wf8YB45nKzOrZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijeetamle/Deep-Learning/blob/master/mnist_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg4-fJBY5E4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specifying tensorflow version 1.x for 1.15.0\n",
        "%tensorflow_version 1.x\n",
        "#import tensorflow\n",
        "import tensorflow as tf\n",
        "#print(tf.__version__)\n",
        "#import MNIST dataset handle from tensorflow and same data in one hot encoded format\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v6cbCe7N-oc",
        "colab_type": "text"
      },
      "source": [
        "**To check whether MNIST dataset got loaded or not**\n",
        "\n",
        "running the below cell will show few images with their labels from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNVped5tEF8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = mnist.train.next_batch(5)\n",
        "images = data[0]\n",
        "labels = data[1]\n",
        "\n",
        "# import matplotlib for visualization\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for index, image in enumerate(images):\n",
        "    print( 'Label:', labels[index])\n",
        "    print( 'Digit in the image', np.argmax(labels[index]))\n",
        "    plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxjr5M5mmuR1",
        "colab_type": "code",
        "outputId": "6b6b370c-e6f6-490e-ce70-171ce690fa5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# defining placeholder\n",
        "# x is a input with 28x28 pixels = 784\n",
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "print('x.get_shape(): {}'.format(x.get_shape()))\n",
        "\n",
        "# y is an output with 10 digits\n",
        "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "# Reshaping the array to 4-dims so that it can work with TensorFlow convolution and pooling functions\n",
        "input_tensor = tf.reshape(x, [-1,28,28,1])\n",
        "print('input_tensor.get_shape(): {}'.format(input_tensor.get_shape()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.get_shape(): (?, 784)\n",
            "input_tensor.get_shape(): (?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKEiqYPWoaKL",
        "colab_type": "text"
      },
      "source": [
        "**Function to create convolution layer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j5iqfeTZ-puj",
        "colab": {}
      },
      "source": [
        "# Function to create convolution layer then performing max pool with stride of 2x2\n",
        "def create_convolution_layer(input_tensor, num_input_channels, num_filters, kernel, stride, name):\n",
        "    print('Name: {} -- input_tensor.get_shape(): {}'.format(name,input_tensor.get_shape()))\n",
        "    # for tf.nn.conv2d create the input shape filter\n",
        "    conv_filter_shape = [kernel[0], kernel[1], num_input_channels, num_filters]\n",
        "    print('Name: {} -- conv_filter_shape: {}'.format(name,conv_filter_shape))\n",
        "\n",
        "    # creating the weights\n",
        "    weight = tf.Variable(tf.truncated_normal(conv_filter_shape,stddev=0.03), name=name+'_weight')\n",
        "    print('Name: {} -- weight: {}'.format(name,weight))\n",
        "\n",
        "    # creating the bias\n",
        "    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_bias')\n",
        "    print('Name: {} -- bias: {}'.format(name,bias))\n",
        "\n",
        "    # setup the convolutional layer operation using weights\n",
        "    con = tf.nn.conv2d(input_tensor, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    \n",
        "    # Define activation operation: add a bias to the output of the convolutional filter, then apply a ReLU non-linear activation function\n",
        "    activation = tf.nn.relu(tf.nn.bias_add(con, bias))\n",
        "\n",
        "    # performing max pooling on activation\n",
        "    # here we are using a 2Ã—2 max pooling window size\n",
        "\n",
        "    activation = tf.nn.max_pool(value=activation,\n",
        "                                ksize=[1, stride[0], stride[1], 1],\n",
        "                                strides=[1, 2, 2, 1],\n",
        "                                padding='SAME')\n",
        "    \n",
        "    return activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ7b1hNqL8ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we have to flatten the output from the last convolutional layer to 1D array\n",
        "\n",
        "def flatten(x):    \n",
        "    \n",
        "    input_shape=x.get_shape()\n",
        "    flatten_num = 1\n",
        "    for index in range(len(input_shape)-1):\n",
        "        flatten_num *= input_shape[1-len(input_shape)+index].value\n",
        "    x = tf.reshape(x, [-1,flatten_num])\n",
        "\n",
        "    print('flatten: {}'.format(x.get_shape()))\n",
        "    return x\n",
        "\n",
        "#    print(x.get_shape())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZcx0_24w9Uo",
        "colab_type": "text"
      },
      "source": [
        "**Function to create fully connected layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oiH4-luU-_bW",
        "colab": {}
      },
      "source": [
        "def create_fully_connected_layer(x, num_output, activation_fun=None, name=None):\n",
        "\n",
        "    # creating the weights\n",
        "    weights = tf.Variable(tf.truncated_normal([x.get_shape()[-1].value, num_output], stddev=0.03), name=name+'_weight')\n",
        "    print('Name: {} -- weight: {}'.format(name,weights))\n",
        "\n",
        "    # creating the bias\n",
        "    bias = tf.Variable(tf.truncated_normal([num_output]), name=name+'_bias')\n",
        "\n",
        "    # Calculate sum of neurons\n",
        "    sum = tf.matmul(x,weights) + bias\n",
        "        \n",
        "        # applying activation function if required\n",
        "    if activation_fun:\n",
        "      sum = activation_fun(sum)\n",
        "\n",
        "    return sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba5Op_CGjcoc",
        "colab_type": "text"
      },
      "source": [
        "**Designing the network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQqa2roLjz2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "8ea8d751-edd8-40b6-c90c-a04dddcbcaca"
      },
      "source": [
        "# Creating convolution layers\n",
        "\n",
        "    # layer 1: 5x5 conv, 1 input, 32 outputs\n",
        "      #   name = layer1\n",
        "      #   input_tensor = input_tensor\n",
        "      #   num_input_channels = 1\n",
        "      #   num_filters = 32\n",
        "      #   kernel = [5,5]\n",
        "      #   stride = [2,2]\n",
        "\n",
        "conv_layer1 = create_convolution_layer(input_tensor, 1, 32, [5, 5], [2, 2],name='conv_layer1')\n",
        "\n",
        "    # layer 2: 5x5 conv, 32 inputs, 64 outputs\n",
        "      #   name = layer2\n",
        "      #   input_tensor = layer1\n",
        "      #   num_input_channels = 32\n",
        "      #   num_filters = 64\n",
        "      #   kernel = [5,5]\n",
        "      #   stride = [2,2]\n",
        "  \n",
        "conv_layer2 = create_convolution_layer(conv_layer1, 32, 64, [5,5], [2,2],name='conv_layer2')\n",
        "\n",
        "# Flattening output to 1D array\n",
        "\n",
        "flatten_output = flatten(conv_layer2)\n",
        "\n",
        "# Creating fully connected dense layers\n",
        "\n",
        "    # layer 1: number of hidden layer nodes = 3136\n",
        "\n",
        "dense_layer1 = create_fully_connected_layer(flatten_output, 1024, tf.nn.relu, name='dense_layer1')\n",
        "\n",
        "    #drop = tf.nn.dropout(dense_layer1)\n",
        "\n",
        "    # layer 2: number of hidden layer nodes = 1024\n",
        "\n",
        "last_layer = create_fully_connected_layer(dense_layer1, 10, tf.nn.softmax, name='dense_layer2')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: conv_layer1 -- input_tensor.get_shape(): (?, 28, 28, 1)\n",
            "Name: conv_layer1 -- conv_filter_shape: [5, 5, 1, 32]\n",
            "Name: conv_layer1 -- weight: <tf.Variable 'conv_layer1_weight:0' shape=(5, 5, 1, 32) dtype=float32_ref>\n",
            "Name: conv_layer1 -- bias: <tf.Variable 'conv_layer1_bias:0' shape=(32,) dtype=float32_ref>\n",
            "Name: conv_layer2 -- input_tensor.get_shape(): (?, 14, 14, 32)\n",
            "Name: conv_layer2 -- conv_filter_shape: [5, 5, 32, 64]\n",
            "Name: conv_layer2 -- weight: <tf.Variable 'conv_layer2_weight:0' shape=(5, 5, 32, 64) dtype=float32_ref>\n",
            "Name: conv_layer2 -- bias: <tf.Variable 'conv_layer2_bias:0' shape=(64,) dtype=float32_ref>\n",
            "flatten: (?, 3136)\n",
            "Name: dense_layer1 -- weight: <tf.Variable 'dense_layer1_weight:0' shape=(3136, 1024) dtype=float32_ref>\n",
            "Name: dense_layer2 -- weight: <tf.Variable 'dense_layer2_weight:0' shape=(1024, 10) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cppVxwzYyYdi",
        "colab_type": "code",
        "outputId": "85460823-73d0-46a7-e4ed-a97adbbed132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(conv_layer1.get_shape())\n",
        "print(conv_layer2.get_shape())\n",
        "print(dense_layer1.get_shape())\n",
        "print(last_layer.get_shape())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 14, 14, 32)\n",
            "(?, 7, 7, 64)\n",
            "(?, 1024)\n",
            "(?, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bI4wXpsSm2m",
        "colab_type": "text"
      },
      "source": [
        "**Define loss and optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DXKIbyDSc-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "47b25b48-824f-42c6-a37f-42f1d9d3f855"
      },
      "source": [
        "# Defining loss\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=last_layer, labels=y))\n",
        "\n",
        "# Adding an optimizer\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
        "\n",
        "# Defining accuracy\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(last_layer, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Adding a summary for storing loss and accuracy\n",
        "\n",
        "tf.summary.scalar('loss', loss)\n",
        "tf.summary.scalar('accuracy',accuracy)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-6382c43b9972>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tKfZ8lWa813",
        "colab_type": "text"
      },
      "source": [
        "**Creating a Tensorflow session**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpjI2MjPbCRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a tensorflow session\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "summary_log = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f_ljKaLorka",
        "colab_type": "code",
        "outputId": "6d58cf16-d1c2-41f0-bbfd-232290e6680b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "batch_size = 50\n",
        "total_batch_size = int(len(mnist.train.labels) / batch_size)\n",
        "print('total mnist training labels: {}'.format(len(mnist.train.labels)))\n",
        "print('total_batch_size: {}'.format(total_batch_size))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total mnist training labels: 55000\n",
            "total_batch_size: 1100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3vhVV5MbeVC",
        "colab_type": "text"
      },
      "source": [
        "**Training the network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wiUCw6WwBPfB",
        "colab": {}
      },
      "source": [
        "# Start time of training\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# initializing the variables\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# for each epoch running the traning of network in batch of 50\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "  print('Starting epoch: {}'.format(epoch+1))\n",
        "\n",
        "  for batch_ctr in range(total_batch_size):\n",
        "\n",
        "    # Fetching a batch size of 50 images\n",
        "    batch = mnist.train.next_batch(50)\n",
        "  \n",
        "    # Every 100 steps, compute & print the accuracy of the network's prediction\n",
        "    if batch_ctr % 100 == 0:\n",
        "      train_accuracy = sess.run(accuracy, feed_dict={x: batch[0], y: batch[1]})\n",
        "      print('step %d, training accuracy %g' % (batch_ctr, train_accuracy))\n",
        "      #print('currently going: {}'.format(batch_ctr))\n",
        "\n",
        "    # run training\n",
        "    sess.run(optimizer, feed_dict={x: batch[0], y: batch[1]})\n",
        "\n",
        "\n",
        "print('Total traning time: {}'.format(time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij8p8F4EDUYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}